---
course: Dynamous Agentic Coding
module: 2
lesson: "2.4"
title: "Validation - An AI + Human Effort"
type: lecture
status: raw
date_added: 2026-02-18
date_modified: 2026-02-18
tags:
  - dynamous
  - agentic-coding
  - module-2-piv-loop
  - validation
  - code-review
key_concepts: []
prerequisites: ["2.1", "2.2", "2.3"]
related_lessons: ["7.1", "7.3"]
---


So our implementation

00:01

is complete and even some parts of the validation. But

00:05

in this video, I wanna show you what the AI

00:07

coding assistant did to validate its own work and how

00:10

it gets that from the structured plan. And then I

00:13

wanna show you how we put ourselves back into the

00:16

process by validating things ourself

00:19

at the very end of this iteration of the PIV

00:21

loop.

00:22

So going back to our diagram here, we just finished

00:25

implementation, leaving it mostly up to our AI coding assistant.

00:28

Now it is time for validation. So I wanna start

00:31

by covering

00:32

the AI coding assistant side of validation,

00:35

then we'll get into human validation.

00:38

And so the 2 core components

00:41

to

00:42

AI validation is

00:44

unit tests and integration tests. So let me show you

00:46

what that looks like. So going back to our code

00:49

base here,

00:50

we have our structured plan. Now I intentionally

00:53

did not cover the validation aspect of this until now.

00:56

So I went over that very quickly in our planning

00:58

video because now I wanna cover that with you in

01:01

more detail.

01:02

And in module 7 of this course and by the

01:04

way, I'm scrolling all the way down because validation is

01:07

the last thing the coding assistant does here. Here we

01:09

go. This is our validation.

01:11

So anyway, in module 7 of this course, I'll get

01:13

into systems for validation. That's when I'll really get into

01:17

the meat of things for you here and how we

01:18

can set up our workflows around validation for both ourselves

01:22

and our coding assistant. But I still wanna cover things

01:24

at a high level here. And so we got the

01:26

unit testing and the integration testing. And the 1 other

01:28

thing that I would consider pretty crucial

01:31

is our linting. So these 3, this is like the

01:33

trifecta of what we want the AI coding assistant to

01:37

create and iterate on

01:38

to make sure our code base is good to go.

01:41

And by the way, it is okay

01:43

if you're newer to coding or using coding assistance and

01:46

you're not familiar or comfortable

01:49

with integration testing or unit testing or linting.

01:53

Because what you can do is as a part of

01:55

your vibe planning stage, when you're initially having that conversation

01:59

with your coding assistant, you can just ask it. What

02:02

should we be testing here to make sure that this

02:04

feature is working properly? And then after that conversation,

02:08

you then use that to build this section of your

02:11

structured plan. So you don't have to be an expert

02:14

software engineer who's done a bunch of linting and unit

02:17

testing before. I know this is a more technical part

02:19

of the plan, but you can use coding assistance to

02:21

help you, not just with deciding the testing to do,

02:25

but even the specific tools to use as well. Like,

02:27

we're using rough in my py for linting and type

02:30

checking. We're using pytest for unit testing. You don't have

02:33

to know all these tools off the top of your

02:35

head. And that's the beauty of using AI coding assistance

02:37

is most things you don't have to know off the

02:39

top of your head because anywhere in your planning, you

02:41

can ask it questions to understand things with these tools

02:45

or your code base or whatever it might be. And

02:47

so really quick here, linting and type checking. This is

02:50

all about making your code base really nice and tidy.

02:53

And not only does that make things more maintainable for

02:55

us and easier for us to review,

02:58

But when you have a really tidied up code base

03:00

where the types are all good, that also helps AI

03:02

coding assistance work on your code going forward as well.

03:05

So this is really, really important. And then unit testing

03:09

is testing all the individual functions that we've created. And

03:12

so, like, for example, having a function to test all

03:15

of the new tools that we've built for the folder

03:17

management for our Obsidian agent. And then integration testing is

03:21

all about taking a step higher and testing functionality

03:24

together. How our different components that we just built work

03:27

together and ensuring that's smooth as well. So those are

03:31

the core 3. And then everything that else that I

03:33

have here like dependency installation and security tests and running

03:36

the full test suite,

03:38

this is nice to have but not extremely important. So

03:41

keep this simple if you want. AI coding assistance will

03:44

sometimes add a little bit more testing than you need,

03:46

but that's totally okay. It worked in our case. So,

03:49

yeah, that's pretty much everything for the AI validation here.

03:53

And so with that, we can move on to human

03:56

validation.

03:57

It is our turn to close the loop here

04:01

and make sure that the code looks good to us

04:04

and asking any questions that we need to understand what

04:06

was changed, and then also running manual tests. And so

04:10

for us, that's gonna be going into Obsidian and making

04:12

sure we can manage folders now. So I'm gonna start

04:14

with the code review and show you some strategies for

04:18

that. And then we'll do the manual testing at the

04:20

end. That's gonna be the big payoff where we get

04:22

to see the new folder management tools in action for

04:25

our Obsidian agent. So pretty excited for that. And so

04:28

for our code reviews here,

04:30

if you have done any coding in the past, you're

04:32

pretty familiar with this. If you worked with the team

04:34

before and they give you some changes, you're set to

04:36

look through file by file and just, you know, kinda

04:39

generally make sure that things look good to you. You

04:42

can be very detailed here, Or if you just wanna

04:45

quickly glance over things, it's all up to you. I'm

04:48

not gonna try to tell you that you have to

04:50

understand every single line of code that the coding assistant

04:53

puts out. You just wanna have a good idea of

04:55

the changes that it made.

04:57

And so 1 thing you can do if you want

04:59

is just go into your coding assistant and say, give

05:02

me a summary of your changes

05:05

and the files that you updated.

05:08

And so this will point you in the direction of

05:10

where you wanna go to look at certain changes. And

05:12

so you can go ahead and do that. The other

05:13

thing that I highly recommend doing, I already said this

05:16

once, is to always have your code bases as git

05:20

repositories

05:21

because then you're gonna be able to look at what

05:23

are called diffs, which is really just the changes made

05:25

to files and new files and deleted files and everything

05:28

since your last save. And so going into my GitHub

05:32

desktop, for example, I'll use this to review AI code

05:36

all of the time. It shows me

05:38

everything that was changed for this fuller management tool implementation.

05:43

So I made that save right after I created my

05:46

structure plan. That's why you don't see it here in

05:48

the change list. And so now everything here is just

05:51

for this single PIV loop. And so I can look

05:54

through and see like, okay, it added a an environment

05:57

variable. Looks good. I'll go to my agent implementation.

06:00

It has a little bit of, an addition here just

06:03

to register the new folder management tools. That looks good

06:05

to me. I can go to Vault security and see

06:08

what it did to add on more security for the

06:10

folder management. And I'm not gonna like show reviewing this

06:13

in detail here. I definitely don't think that's worth your

06:15

time. But just generally showing you how I'll go through

06:18

the files that are created and the ones that are

06:20

updated and just checking that that all looks good. And

06:23

then going back to the response from our coding assistant

06:25

here, if we don't wanna do something and get directly,

06:27

we can always just go off of something like this.

06:29

So it gives me this really nice summary here of

06:32

the files that are created,

06:34

the files that are modified, and then I can select

06:37

any 1 of these that I wanna go into and

06:38

validate just like I did in the GitHub desktop app.

06:40

So for example, I can go to,

06:43

source, shared, and I can go into my vault security

06:46

and I can take a look at everything there. Like,

06:48

this is 1 of the new things that was added

06:50

for example for the folder security.

06:53

And it's really up to you how much you want

06:55

to validate things like I said. And if you are,

06:58

again, newer to coding in general and you don't really

07:02

trust yourself to look at this code line by line,

07:05

the way that I would recommend validating

07:07

is just asking some questions. Like for example,

07:10

what did you implement

07:12

as far as folder security? Or maybe it's you have

07:16

in mind, like, okay, I need to make sure that

07:17

it can only create folders within my vault. And so

07:19

you can ask it, like, did you implement something to

07:22

make sure that you can't create folders anywhere on the

07:24

computer? Just as a random example. Right? So, like, you

07:26

can still validate even if you aren't looking at the

07:29

code directly because you can ask questions to make sure

07:32

the coding assistant

07:33

thought about all of these little granular things as it

07:36

was going through the implementation because you might not all

07:39

have all of the tiny, tiny details for things like

07:42

folder security laid out in your structure plan. And so

07:44

you can still validate that at the very end here.

07:47

So, yeah, based on this answer, it clearly thought about

07:50

security for the folder tools here. So for example, it

07:53

blocks invalid characters, won't even try to make the folder

07:56

there.

07:57

It handles empty and, white spaces and names, critical folder

08:00

protection,

08:01

path traversal protection. I'm not even gonna dive into all

08:04

these things here, but it's very nice that it thought

08:07

through all of this. And so, yeah, very thoughtful implementation.

08:10

So I'm able to validate just kinda through having a

08:13

conversation. So your validation can almost go back to vibe

08:15

planning in a sense. But instead of planning, we're now

08:18

just asking it questions to make sure we're on the

08:21

same page that the coding assistant understood everything it needed

08:24

to make. And so the very last thing that we

08:27

have to do, that's code review at a high level.

08:29

Now I wanna talk about manual testing. And so manual

08:32

testing is literally as simple as starting up the application

08:36

and asking your coding assistant how if you need to,

08:40

and then trying it out. Just how would a user

08:42

normally interact with this application? Let's see if it works

08:46

now. So for example,

08:48

I have the new version of the agent up and

08:50

running in my terminal already. So I'm gonna open up

08:52

my Obsidian folders here so you can see all the

08:54

folders that I currently have And I'm gonna go into,

08:58

my Copilot here. So I'm gonna open up the right

09:00

hand bar here, and I'm just gonna say hello. I'm

09:03

gonna make sure that I'm connected to my agent here.

09:05

There we go. Got a response. And then I'll say

09:07

create a folder called test folder. So literally just simple

09:12

requests here as if I'm a user just wanting to

09:14

do something in my Obsidian vault. And there we go.

09:16

We created

09:17

our test folder. Nice. And I can even say, like,

09:20

make a simple,

09:22

file in here,

09:24

put some random text. And so just making sure that

09:26

I can now operate within this folder as well. And

09:29

there we go. Created a simple

09:31

file dot MD within here, and alright. Looking good. So

09:34

this is perfect. And I can say now, rename this

09:37

folder to test folder 2. So So just going through

09:40

the different tools that I know that it added based

09:42

on the summary it gave me, making sure that works

09:44

and that the file still lives in there. Nice. Nice.

09:47

Alright. And then I'll just say delete this folder, which

09:49

I really hope it understands. It doesn't delete the wrong

09:52

folder here.

09:53

I pray that that okay. There we go. So the

09:55

folder is not empty and contains files. Okay. So please

09:59

confirm. This is actually really nice. I appreciate it doing

10:01

this. It's only letting me delete the folder if there's

10:03

nothing in it, or I can do a forced deletion.

10:05

So I'll say, yeah, do a

10:07

forced deletion.

10:08

So that's kind of like an edge case that I'm

10:10

testing as well. Like, can I delete a folder even

10:12

if there's something in it? And sure enough, this is

10:14

working exactly

10:16

as I want it to. And as you are validating

10:18

things through a code review or through manual testing, if

10:21

anything doesn't look perfect to you, all you have to

10:24

do is go back into your AI coding assistant

10:27

and just say something like, the security

10:32

is too tight or whatever you want to do. Right?

10:34

Like, if there's little issues that you have in your

10:37

code base with this new implementation,

10:40

you don't have to go all the way to the

10:42

beginning of the PIV loop again and start by planning

10:46

these bug fixes. Like, if it's small enough, you can

10:48

just do 1 off prompts here to address these things.

10:52

And then later when we talk about creating systems, that's

10:54

when I'll guide you through whenever there's an issue, we'll

10:57

improve the system and use the system to retry. But

11:00

in a basic sense right now for these little things

11:02

that you might wanna tweak, just go ahead and throw

11:04

the prompt into the coding assistant. And if the implementation

11:07

is terrible enough where you really want to start over,

11:11

that's why I had you create a save state in

11:12

git right after creating the structured plan. Because literally what

11:15

I could do here

11:16

is I can just right click on these changes, discard

11:19

all. So it's gonna take me right back to the

11:21

code base with the structure plan before I did anything,

11:24

and then I can just execute the structure plan again

11:27

or maybe tweak my structure plan based on the things

11:29

that it did incorrectly and try again.

11:32

And also, I'm doing this in GitHub desktop but you

11:35

could just do this in the command line or literally

11:37

ask the coding assistant to,

11:39

revert all current changes

11:42

in git. And it'll go ahead and just take care

11:44

of that for you. So any of the more technical

11:46

things I show you with Git, you can literally always

11:48

just use your AI coding assistant to help you with

11:50

that. And so, yeah, that is pretty much everything for

11:53

validation. So we had all of our linting, unit testing,

11:55

integration testing, that was all good. We also did all

11:58

of our human in the loop testing with our code

12:02

review and manual testing. At this point, I am very

12:05

confident in this rather simple implementation, so I would call

12:09

this the end of the PIV loop. And now our

12:12

next iteration, right, because it is a loop. When I

12:14

go back to planning, that's just gonna be for the

12:16

next feature that I implement. Like, maybe I wanna add

12:18

more tools into my agent. I don't wanna try to

12:21

add too much at once. And so if I have

12:23

this idea of, like, 10 different tools I wanna add

12:25

to my agent, well, I'll split it up into

12:28

10 iterations of the PIV loop. And so now it's

12:30

my time to just go on to the next 1.

12:32

Right? And so the next time we go through the

12:34

PIV loop, I'm actually gonna show you building the Obsidian

12:37

agent completely from scratch. And then in future PIV loops

12:41

in this course, we'll do something similar. We'll just be

12:43

adding more tools, more capabilities to our agent going through

12:46

this process, but we're gonna be doing it as a

12:48

system. So we'll really get into global rules and slash

12:51

commands, automating all of this, even getting into remote agent

12:54

decoding. There's a lot more advanced and fancy stuff coming

12:57

up soon. Don't you worry. And so with that, now

13:00

that we have an understanding of the pivot loop and

13:02

you saw it in action, it is time for our

13:05

next exercise.