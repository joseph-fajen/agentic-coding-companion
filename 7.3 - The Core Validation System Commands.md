---
course: Dynamous Agentic Coding
module: 7
lesson: "7.3"
title: "The Core Validation System Commands"
type: lecture
status: raw
date_added: 2026-02-18
date_modified: 2026-02-18
tags:
  - dynamous
  - agentic-coding
  - module-7-validation
  - validation-commands
  - execution-report
  - system-review
key_concepts: []
prerequisites: ["7.1", "7.2"]
related_lessons: ["7.4", "8.1"]
---

Now it is time to see our code review command

00:02

in action and then we'll even go over our second

00:05

command to fix the issues that are brought up in

00:08

the code review report. Now we're gonna do all of

00:10

this on the PIV loop that we did 2 videos

00:13

ago. So I have the code review command loaded up

00:16

in the Obsidian agent. This is the exact same command

00:19

that I covered as a solution in the last exercise.

00:22

Then I also have the code review fix command. I'll

00:24

go over this more with you once we get to

00:26

the point where we're executing this. And so there's 1

00:30

little awkward thing that I have to explain to you

00:32

here just so you understand how I'm performing the code

00:35

review. Remember from the last video, typically you're going to

00:38

perform the code review after the implementation

00:40

before you make the commit because we only wanna make

00:43

that save state once everything is fully validated.

00:46

However, and you can see this here, I asked for

00:48

a summary of the last commits. I have already committed

00:52

the implementation

00:53

from our last PIV blue because I had to do

00:56

that just to show you everything with the validation as

00:58

we are fixing our linting issues and everything,

01:01

that I showed you earlier.

01:03

And so I have to use this code review command

01:05

a little bit differently here than I typically would because

01:08

I needed to look back on a previous commit and

01:11

then analyze the changes there. So instead of just you

01:14

doing a git diff and finding out what changed from

01:16

the last commit, I have to have it search back

01:19

a little bit more. So it's the same idea. I'm

01:21

just explaining here what I have to do a bit

01:24

differently for this demonstration.

01:26

And also it's kind of neat that even after you've

01:28

committed things, you still can have a code review go

01:31

back and look at different commits. And so that's what

01:33

I'm showing you right here. So I asked for a

01:36

summary of my latest commits.

01:37

This is the 1 where I did the implementation for

01:40

the last PIV loop. And so now I'm saying list

01:42

out all the files that were updated or created

01:45

in this commit specifically. And so it doesn't get show.

01:47

It finds the files that are changed. And now I'm

01:49

gonna use this as context to go into the code

01:52

review. So I'll do slash code review, and that's in

01:55

the validation folder.

01:56

And then typically you don't have to provide extra context

01:59

here as an argument but I'm just going to say

02:02

perform a code review

02:04

on this commit

02:06

specifically.

02:07

And so that way it knows to adjust its git

02:09

commands that I have in the instruction set there to

02:12

work with analyzing these modified and created files. So cool.

02:16

I'm gonna go ahead and send this in, and this

02:18

is a more generic code review command that's going to

02:20

analyze all kinds of issues, performance, security,

02:23

any kind kind of linting, things like it'll it'll look

02:25

at it all. So it'll come back once it's done

02:27

with its report. So the big code review has finished,

02:31

and thank goodness.

02:32

It says approved, ready for merge. It says that my

02:35

quality

02:36

is excellent.

02:37

So absolutely fantastic. And it actually is pretty amazing. So

02:41

going through this review, like, everything is just in tip

02:44

top shape. Like, our system is working wonders for us

02:47

right now. We have excellent type safety, comprehensive testing, strong

02:51

documentation. Our documentation is being kept up to date. The

02:54

logging standard is continuing to be respected that we have

02:57

as a part of our layer 1 planning and our

02:59

rules. The architecture compliance is phenomenal with the vertical slice

03:03

Architecture that we have in our on demand context. Like,

03:05

man, everything is really coming together here in module 7.

03:09

We can see that as we are validating things. And

03:12

so there are no high severity issues found even after

03:15

we've done quite a few PIV loops here. And so

03:18

I know that it only analyzed specifically

03:20

that commit for our last PIV loop, but, yeah, I

03:22

mean, we've been implementing a lot of things that affect

03:25

every area of our code base.

03:27

And so just a couple of medium severity issues and

03:30

then a couple of low severity issues. And I ran

03:32

through this already off camera and man this is some

03:35

really small stuff. And it turns out that like even

03:37

this first medium severity issue with it maybe not like

03:40

this tool in particular maybe not working with very large

03:43

vaults. It's even already documented in the code. So our

03:47

system really does understand everything already. It's just there is

03:50

a little bit of room for improvement. So not bad

03:53

at all. This is this is fantastic. And so at

03:56

this point, we have this report, and so we're ready

03:59

to execute on this. I want to create a command

04:02

where the input is going to be this report and

04:05

it's going to leverage that to think through each of

04:08

the issues here, find a fix for each 1, implement

04:11

each 1, and then report back to me what it

04:13

did. And so really the output of our code review

04:17

command is the input. Like we have to think about

04:19

it that way that we want this review to this

04:22

file to be structured in a way where it's optimal

04:24

and comprehensive input going into the next command. And so

04:28

that's what I have here already in the validation folder

04:30

and I have this in the main repository as well

04:33

as yet another command for you to reference and build

04:36

on top of. It is our command to do a

04:38

code review fix. And so very simply, it starts by,

04:42

I ran or performed a code review and found these

04:45

issues.

04:45

And then we can either give it a path to

04:48

a file

04:49

or a description of the issue because maybe we want

04:51

to describe the problem ourselves

04:54

instead of going off of some file that the coding

04:56

assistant generates. And so this is flexible to work with

04:58

either an output that we wanna pass in from the

05:01

coding assistant or us just speaking to some problem that

05:04

we noticed during our manual testing. So please fix these

05:07

issues 1 by 1. And then if it is a

05:10

code review file, then make sure you read the entire

05:12

file to understand all the problems that are presented there.

05:15

And then an optional argument for the scope. If there's

05:17

anything we wanted to focus on in particular

05:20

when it is addressing the code review. And so for

05:23

each fix, explain what was wrong, show the fix, create

05:26

and run the relevant test to verify. And then after

05:28

all the fixes, I'm going to have it run our

05:31

validate command that we covered 2 videos ago to finalize

05:34

everything, make sure that we have 1 comprehensive sweep over

05:37

the entire code base so that we're good to go.

05:40

So back over into cloud code, we can now do

05:42

slash code review fix. And if you're using any other

05:45

AI coding assistant, just point it to read the file,

05:47

and now we specify our 1 argument here, which is

05:50

gonna be the path to our review.

05:53

And so also because the argument could also just be

05:56

our own description, this is where we can manually ask

05:59

it to fix a certain issue that we noticed ourselves.

06:01

Like, I could say I ran the app manually

06:05

and noticed that none of the tools are working.

06:09

Please fix it. Alright. I'm not gonna do this here

06:12

and the tools are actually working. But just as an

06:14

example, where if we want a bit more of an

06:16

informal process just just for our manual testing, we can

06:18

do that. But I'm gonna go ahead and copy this

06:20

code review. I'm just gonna copy the relative path, paste

06:23

it in, send it off to the races. And so

06:25

it is going to address literally everything. Now be careful

06:28

if your reviews are very long and there's like 20

06:31

things it needs to address that's probably going to overwhelm

06:33

it. And so that is why I specifically have the

06:36

second argument for the scope. So we can say just

06:39

focus on these 3 issues or just this single issue.

06:42

So you can make it more granular if you need.

06:44

And this is a really simple command that you can

06:46

definitely evolve to your code base as well. I just

06:49

wanted a good starting point for our demonstration here. So

06:52

I will come back once it has handled our issues.

06:55

Alright. Our fixes are done, and man, is our code

06:58

base looking phenomenal.

06:59

Check marks across the board. It addressed everything except for

07:03

2 of our issues.

07:04

And so I actually kinda like that it has the

07:07

intelligence here to not just address literally everything, but do

07:10

a bit of review. Like, oh, the review concluded that

07:12

we don't actually need to address this, so let's just

07:15

enhance the documentation.

07:16

And then for this 1, the documentation said that it's

07:19

acceptable as a part of the MVP

07:21

so we can market for a future enhancement. Like, this

07:23

is really neat. And if you disagree with any of

07:25

these things, just ask it. Ask it why it did

07:28

what it did. Ask it to actually go and address

07:31

that issue. It's totally up to you. And if you

07:34

find, for example,

07:35

a pattern here where it's ignoring a lot of these

07:38

issues and saying it shouldn't address them when you think

07:40

it should, well, that's an opportunity to evolve your system.

07:43

You can evolve

07:44

the process of creating the reviews

07:46

or evolve your command for fixing the code reviews. And

07:50

so up to you how you want to address anything

07:53

that you don't agree with here. But I think that

07:55

this is looking fantastic. So I'll just go ahead and

07:58

run my commit here. I've got a really good save

08:00

state, and this is what I've got right now for

08:03

the code base for module 7. And I will say

08:06

that as I'm continuing to evolve this agent throughout the

08:09

course and even outside of the videos, things might change

08:12

a good amount. And so if you're following along, like,

08:15

I always make sure that you're reading the read me

08:17

for the project if the setup instructions change. Like, for

08:20

example, at some point, I probably wanna run the agent

08:23

in a Docker container along with Postgres instead of just

08:26

directly

08:27

on the computer with Python. So, yeah, there might be

08:29

things that I change. I really am building this from

08:31

scratch with you, and so there are a lot of

08:33

things to improve, but man, things are looking really really

08:37

good right now. And it's good to have these little

08:39

issues that we want to improve upon and review because

08:42

then it allows me to demonstrate every part of our

08:45

system. So there is our commit. We are good to

08:48

go. Okay. And then 1 last really tiny thing I

08:50

wanna cover here is that a lot of these documents,

08:53

these markdown files that we have created in the dot

08:55

agents folder, you don't always want them checked into your

08:57

git source control. And so feel free to add any

09:00

of the dot agent folders to your dot git ignore.

09:04

That way you're not pushing all these things and you

09:06

can keep it as just local context, like all your

09:09

code reviews, maybe even your plans. You might not necessarily

09:12

want to push them for everyone to see or just

09:14

to bloat your repository. So just wanted to mention that

09:17

quick. But with that, that is everything that I have

09:19

for you with our code reviewing and fixing based on

09:23

those reports. And this is an optional part of the

09:26

PIV loop, but it really is a good enhancement of

09:28

your validation system to go along with everything you're doing

09:31

to close off a PIV loop. And so with that,

09:35

in the next video, I wanna cover

09:37

a system for improving our system. Talk about a couple

09:41

of commands for that, show you that in action, and

09:44

I even have an exercise for you to build your

09:46

own system improvement command. So I'll see you in the

09:49

next video for that.