---
course: Dynamous Agentic Coding
module: 5
lesson: "5.5"
title: "Build Our AI Agent (PIV Loop, Layer Two Planning)"
type: lecture
status: raw
date_added: 2026-02-18
date_modified: 2026-02-18
tags:
  - dynamous
  - agentic-coding
  - module-5-planning-system
  - layer-2-planning
  - piv-loop
  - vibe-planning
  - structured-plan
key_concepts: []
prerequisites: ["5.4"]
related_lessons: ["5.6", "6.1"]
---


Alright. Now it is time for the fun part. This

00:03

is our big payoff.

00:04

We have all of our layer 1 planning done, and

00:07

now it's time to do the first iteration of our

00:09

PIV loop focusing on layer 2 planning to build our

00:13

Obsidian agent from the ground up. I'm super excited for

00:16

this because there's so much work that we put into

00:19

our layer 1 planning. Going back and forth with the

00:21

coding assistant to create our PRD and our rules and

00:24

our on demand context and our commands for our system.

00:26

And so now when we get into the PIV loop,

00:29

we have all of that to launch ourself through these

00:33

iterations.

00:34

And so things are gonna go pretty quickly here, not

00:37

because we're vibe coding, but because we spent so much

00:40

time creating all this context upfront and because as a

00:43

part of our system we're gonna go through the PIV

00:45

loop in small iterations focusing on subsets of our PRD

00:50

just taking individual tasks and knocking them out throughout this

00:53

loop here. And so in this video, we're gonna go

00:56

through Vy Planning. We're gonna pick something out of the

00:58

PRD, implement it to start our agent. We'll create our

01:01

structured plan, and then I'm not gonna cover the implementation

01:05

validation too much because that's what modules 6 and 7

01:08

are for, but we still will go through the whole

01:10

PIV loop just focusing on the planning. So our layer

01:14

1 is done done. We are completely

01:16

ready to move to layer 2 to have the big

01:19

payoff of starting to implement things very rapidly

01:22

thanks to the context and system that we have created.

01:25

Alright. Let's get right into it. So I'm gonna open

01:27

up cloud code, and 1 thing I wanna show you

01:30

from the conversation from the previous video is I ran

01:32

the commit command. And so I created a save state

01:36

here right after I finished my layer 1 planning. And

01:38

I did update the read me to change it from

01:40

the template 1 to the 1 for our AI agent

01:43

as well. So I have the save state. Now I'm

01:45

gonna move into layer 2 planning, creating the structure plan,

01:48

and implementing. If there's any mistakes that happen there that

01:50

are bad enough or I wanna completely revert to this

01:53

current state and retry,

01:55

I can do that. That's my opportunity as well to

01:57

evolve my system and retry. Like, I'm always saying you

02:01

should be focusing on. So, yeah, with this now, I'm

02:04

going to do a slash clear and we're ready to

02:07

start a brand new conversation

02:09

planning things from scratch. Let's think about what we want

02:11

to build as the first iteration of our agent and

02:14

create the plan for that. So if you went through

02:16

all of module 4, you probably know what is coming

02:19

first. The very first thing I wanna do is I

02:22

wanna run the prime command. That is the first part

02:25

of my system that I'm going to leverage right now.

02:28

And so within my dot cloud folder and commands, I

02:30

have the prime command. This is what I'm going to

02:33

leverage

02:33

to get the AI coding assistant caught up to speed

02:36

on my template.

02:37

Now if you are truly starting from scratch,

02:40

you might not need to use the prime command.

02:43

I'm just doing it because I have a template so

02:45

even though it's the first PIV loop to get our

02:47

agent off the ground, I still have some things to

02:50

analyze like our template code and the read me that

02:52

we have created based on our PRD,

02:55

things like that. So I'm gonna go into here and

02:57

just do a simple slash prime, a very generic prime

03:00

command that I have here that you can leverage that

03:02

will really work for any code base at all. It

03:05

even is agnostic to the programming language that you're using.

03:08

I call it a couple of different languages here. And

03:10

so remember for module 4, we do also have the

03:13

command

03:14

specifically to prime the coding assistant for building tools, but

03:17

we're not going to do that yet. We're gonna create

03:19

the base agent,

03:21

and then we will add tools on in future iterations

03:23

of the PIV loop. So we're keeping it so simple

03:26

at first that we're not even doing any tools yet.

03:29

And so basically, we'll just be an LLM that we're

03:31

getting ready to attach into Obsidian,

03:34

then we'll add on some tools and future PIV loops.

03:36

And so we're going to just extract the the very

03:39

basics of the agent from the PRD. That's we're gonna

03:41

be building right now. Alright. Priming is complete. It says

03:45

we got a solid infrastructure with 0 technical debt. Very

03:48

proud of that. But the core agent features are entirely

03:51

unimplemented,

03:52

which is perfect. We want it to recognize that. If

03:55

it thought that something was already here besides the template,

03:57

that would be a problem. So I've read through all

03:59

this off camera, and it definitely understands our code base.

04:02

You do want to take a look at that because

04:04

remember, we are formatting the output from the prime command

04:07

be human readable so we can validate the coding assistance

04:10

understanding. That's part of our system here. And so the

04:12

next thing, now that we have the priming complete, it's

04:15

time to move on to vibe planning. We just wanna

04:18

think about the next thing to build and start doing

04:21

the planning around it. And so here's what I'm gonna

04:23

do. This is awesome. We don't even have to know

04:26

what comes next necessarily. I can literally just tell the

04:28

coding assistant to,

04:30

take a look at

04:32

and then I can reference dot agents slash p r

04:35

d dot m d and help me think about what

04:38

I should build

04:40

first. Right? Like, building first because it is entirely unimplemented

04:44

right now.

04:45

And so, yeah, maybe I do have an idea what

04:47

I should build first. Like, I wanna build the agent

04:49

first. I want to build a connection to the Obsidian

04:51

plug in first. But I don't have to know. I

04:53

can explore that with the coding assistant. That's the whole

04:56

point of Vibe planning. However you want to approach getting

04:59

on the same page with the coding assistant and what

05:01

has to be built, you can do it. And so

05:03

right here, I'm assuming we don't even know just for

05:06

demonstration purposes. Okay. Cool. It read through our PRD. It

05:09

did some analysis on some other files in our code

05:11

base here, and it has a recommendation of things to

05:14

do in order to get to the point where we

05:16

have a fully working agent

05:18

operating in our Obsidian Vault. Now obviously, we're not gonna

05:20

go that far right now, but actually the first thing

05:23

I wanna call out is that I disagree with what

05:25

it's proposing here because it wants to build out the

05:28

vault manager with some of the functions that'll be used

05:31

as agent tools

05:32

before we build the agent itself.

05:34

I don't actually like that. I wanna start by building

05:36

the agent. And generally, when I'm building any kind of

05:39

agentic application I always will start by setting up the

05:42

connection to the LLM, getting the agent with the system

05:45

prompt and then I'll add in tools and other things

05:47

like the Obsidian connection after. And so I'm gonna paste

05:50

in a prompt that I have

05:51

pre curated here just to keep us going. So I'm

05:54

gonna say I disagree with the approach. I actually wanna

05:56

start by building the agent itself. And since we are

05:59

leveraging Pydantic

06:00

AI, I wanted to do deep research on Pydantic AI

06:04

itself. Figure out how we can build just a simple

06:06

base agent.

06:08

I wanna use anthropic as a provider,

06:10

but I do want to make it OpenAI compatible at

06:13

some point. But again, just keeping it simple. We want

06:16

every PIV loop to be a small iteration so that

06:19

things are gonna be a lot more reliable. We can

06:21

trust the coding assistant. Our system plus keeping things simple

06:25

is what's gonna lead to getting incredible results even as

06:27

we start to do more pivot loops and really start

06:29

to build out something more advanced.

06:31

And so the other thing that I'm calling out here

06:33

is I wanted to read the vertical slice architecture article

06:37

that I brought into to my reference folder. So I

06:39

wanted to leverage this because that's definitely like as we're

06:42

creating the initial AI agent here defining our initial code

06:46

structure, it is very crucial that it loads this on

06:49

demand context that we curated as a part of our

06:52

layer 1 planning.

06:53

And so not implementing anything yet, just researching,

06:56

but it's going to, through our vibe planning here, starts

06:59

to tell me how it's gonna implement this agent. We

07:02

can have a conversation back and forth to refine our

07:05

understanding together. Alright. It is back from its research, and

07:08

you know the drill because we already went through the

07:10

PIM loop in module 2 and creating the PRD recently,

07:13

very similar process.

07:15

Read through everything and make sure we're on the same

07:16

page. 1 thing that as I read through this off

07:19

camera, I didn't quite understand

07:21

exactly

07:22

what it's going to be building here because it laid

07:24

out phase 1 what I asked for, but then it

07:26

goes further. It talks about building the first tool, which

07:28

I do wanna do in a separate PIV loop, talks

07:30

about OpenAI compatibility, which I wanna do that as the

07:33

next PIV loop actually. So I'm a little confused.

07:36

And so just as an example of the kind of

07:37

question you can ask is, okay, based on this, what

07:41

would you actually implement

07:43

now to start? Like, okay, you've listed out quite a

07:45

bit of information here of things that we can do

07:47

in phases, but, like, are you gonna start with phase

07:50

1 or try to do a lot at once? Making

07:52

sure that we know

07:53

what it is looking to do first. And this is

07:56

looking really good. So what it's gonna implement right now,

07:59

keeping it nice and simple, it's going to add the

08:01

Podantic AI dependency because we call call this out in

08:04

our tech stack and our rules and PRD, but it's

08:06

not added to our project yet. It's gonna update configuration,

08:09

create our base agent, just keeping it simple, and then

08:12

it's going to create an API endpoint leveraging the fast

08:15

API part of our template. So it's good that it

08:18

recognizes that, and then it's going to just test the

08:20

endpoint to make sure that our super base agent is

08:23

working well. So very good.

08:25

There's nothing with adding tools to the agent yet. We're

08:28

really just creating a connection to the LLM,

08:30

creating a system prompt, and adding in 1 API endpoint

08:34

to work with it and validating that. And that is

08:36

beautiful. And trust me, you can take your PIV loops

08:39

very far as your system gets more refined and elaborate.

08:43

But it's good to keep things simple when you want

08:45

to be the most reliable, especially

08:48

when we are just starting our code base because you'd

08:50

be surprised how much has to get created at first

08:53

just to kind of create that initial scaffolding for your

08:56

project. And so I want to keep things simple because

08:58

it is still gonna create a good amount here. And

09:01

so, yeah, I'm gonna call this for the vibe planning

09:03

stage now. Obviously, in general, I go back and forth

09:06

quite a bit more, but just to keep things chugging

09:08

along, I am ready now to create our structured plan.

09:11

And you've saw this before in module 2, we did

09:13

the fib loop the first time. But now we are

09:16

gonna be using a command to do all of it.

09:19

So no more manually typing the research request and outlining

09:23

the structure for our plan. Now that is all a

09:26

part of the plan template.

09:28

And so this is how we are evolving from when

09:31

you first saw the pivot loop. Commands, like I said

09:33

in module 4, is really gonna be a big part

09:35

of our system because now we're barely typing anything as

09:38

we get our agents started. That's the beauty of it.

09:41

And so this planning command is a simple version of

09:43

the core planning command I showed in module 4 because

09:46

it will be your exercise in this module to add

09:48

in the research part of the planning command. And so

09:52

most of the time for planning, I have it do

09:53

additional research because usually there's more it has to do

09:56

than just what we did in the Vybe planning stage.

09:59

And then after the research, it will fill in the

10:01

template that I define here, which you can always have

10:04

this as a template extracted out of the command,

10:07

or just what I do right here works well. Right?

10:08

Just inject it right as a part of the context

10:11

for the command itself. So it is always research and

10:14

then fill in the plan. And then at the very

10:16

bottom here, if I scroll all the way down, I

10:18

also describe where to output this plan because this is

10:21

going to be the input for our execute command. So

10:24

we won't talk about the execute command too much because

10:26

that is the next module, but they really do go

10:29

hand in hand especially because some of the sections of

10:31

our structure plan like the implementation,

10:35

for example. The way that we describe the tasks here

10:38

is going to work directly with how in the execute

10:40

command, we tell the coding assistant how to knock things

10:42

out task by task. And so in the last module,

10:45

you already created

10:47

your own structure for a plan. So now you can

10:49

just inject this right into this plan template command, and

10:53

then you'll add on the research phase once you get

10:56

into the next exercise. So again, we got our user

10:58

story, problem statement,

11:00

our relevant files that we want to edit in the

11:03

template and things that we want to reference like other

11:05

examples we brought in. This should all look very familiar

11:09

to you. I'm not changing things that much on purpose

11:11

because this really is a solid structure for us to

11:13

follow here. We have the task by task implementation plan

11:16

that will play really well into our execute command in

11:19

the next module. We have, of course, validation and our

11:22

testing strategy as well because we want as a part

11:24

of the structure plan execution for the coding assistant to

11:28

check its own work. So it can iterate and validate

11:30

things before we even get our hands on it at

11:32

the end in the validation phase, which we'll get into

11:35

in module 7. So this is our plan at a

11:38

high level, going to the coding assistant. Let's use this

11:41

now. So scrolling back down to the bottom of our

11:43

conversation now, I have a prompt pasted in here ready

11:46

to send in already, just to save us a little

11:48

bit of time. And so I'm doing this here to

11:50

show you that we have our Vybe planning stage complete,

11:53

but we can always just add in more context before

11:55

we get right into creating the structure plan. So I

11:58

could just do slash plan template and that's it, and

12:01

it'll leverage all of our existing conversation to create the

12:03

structure plan. But, yeah, it's just nice to, like, add

12:06

in some other last minute things as well. Like, for

12:08

example, I wanna use Claude Haiku 4.5 as the model

12:11

because it did want to use I forget where I

12:14

saw it up here, but it wanted to use Claude

12:16

Sonnet 4.5. So I just wanna use a cheaper model.

12:18

So that kind of thing,

12:20

making sure that it says using Python dot e n

12:22

v for loading my environment variables. So I'm just making

12:25

sure that I'm applying my own knowledge to reduce the

12:28

number of assumptions the coding assistant is making. That's all

12:30

that this comes down to. And so if you are

12:33

not as comfortable with just, like, adding in all these

12:35

opinionated things, you don't need to. Like, don't feel like

12:37

you have to do it like this, but I'm just

12:39

providing as much context as I can going into creating

12:42

the structure plan. So I'm gonna go ahead and send

12:45

this in and boom, off to the races. It'll immediately

12:47

read all the context in our plan template command

12:51

and it will execute them on it. So there we

12:53

go. I'll come back once we have our structure plan.

12:56

Plan is done. Now let's validate things. And so first

12:59

of all, what do I get? I like that it

13:01

said this. What do you get? After completing this plan,

13:04

you have a working agent that talks with Claude Haiku

13:06

4.5, at least just as our model to start, and

13:09

we have a single endpoint to test it out. And

13:11

then after this, as we can build the vault manager

13:13

and tools and things like that. So this is looking

13:16

really good but now I want to take a look

13:18

at this plan and make sure I understand everything before

13:22

I implement.

13:23

And yeah, the first thing that I notice here is

13:26

that this plan

13:28

is probably too long. It is over 1000 lines

13:32

of text and for a more basic start to a

13:35

project like this, I definitely do not need that much

13:37

information in my structured plan. Now if I were to

13:40

execute this right now, it would probably be fine, but

13:44

I want to show you what it's like to iterate

13:46

at least a little bit and that is 1 of

13:47

the first things and something that you're going to see

13:50

quite a bit where you just wanna make things more

13:52

concise. Because,

13:54

yeah this is for an agent to use in the

13:57

execute command so it's okay if it's rather long but

13:59

I still want it to be kind of human readable

14:02

and I would say that 1000 lines for this kind

14:04

of feature is definitely too much. And so I'm gonna

14:06

go into the coding assistant and just say that this

14:08

is

14:09

too long. Make it more concise and then remember remove

14:13

assumptions from the coding assistant how long do we want.

14:16

I'm gonna say make it, between

14:19

507

14:20

hundred lines long. So I'm I'm leaving a bit of

14:23

room, a bit of flexibility here between, you know, a

14:26

couple hundred lines plus or minus, but yeah, I don't

14:29

want it to be that long. So I'm gonna send

14:31

this in, come back once it is more concise. Alright.

14:34

Now we have something that is a reasonable length. 558

14:38

lines from almost 1100.

14:40

Okay. Let's take a look at it now. So open

14:42

up the preview again. Well, first, let's see the line

14:44

numbers. So, yep, 558.

14:47

And going to the preview, this looks much, much better.

14:50

So feature description, we wanna create a foundational pedantic AI

14:53

agent, so good. Keeping it simple. User story, problem statement,

14:56

we're following the vertical slice architecture patterns that we have

15:00

in our on demand context because we call that out

15:02

as a part of our planning. Very, very good. Future

15:05

metadata, context references,

15:07

looking really good. Just concise little references to the parts

15:10

of the code base that we care about here, the

15:12

new files that we need to create. I appreciate it

15:14

listing this out. Like, it really seems to understand the

15:17

implementation, and that's the main thing that I wanna validate

15:19

as I'm going through the structured plan here. Relevant documentation

15:22

to read during the implementation,

15:24

looking really good. Just calling out some of the specific

15:27

documentation pages from Pydantic AI.

15:30

Patterns to follow. So from its analysis of the code

15:34

base and probably some things from the PRD as well,

15:36

it's getting all of this information. So I like this

15:39

a lot. We got the step by step implementation that'll

15:42

help for execution. So that is really good too. And

15:45

last thing I'll show really quick is just the,

15:48

validation that we have baked in here. So let's scroll,

15:50

scroll, scroll. Quite a few tasks because it's really making

15:53

things granular. I think that's definitely a good thing. Like

15:56

even tasks for creating each of the individual files. I

15:59

mean, that's totally good as well. You can have quite

16:01

a few tasks as long as it's not taking up

16:03

way too much context, which now that our file is

16:06

nice and concise, I think that is totally fine. So

16:08

okay. Here is our testing strategy. So we're going to

16:10

do unit tests and then integration tests and then it's

16:14

going to cover any edge cases here. And then I

16:17

was just about to say, I think it's missing the

16:19

linting here, but this is a part of the validation

16:22

commands. And so level 1, syntax and style using,

16:26

my py and rough. So that's good. And that's a

16:29

part of what's built into this template, by the way.

16:31

It's things for linting and standards for, like, logging and

16:34

testing. Like, all of that is going to play into

16:36

our structured

16:37

plans, but also you don't need a template to get

16:40

to this point. It can be a part of your

16:41

global rules as well. So yeah. Okay. This is looking

16:44

really, really good. Okay. So I would call this plan

16:46

ready to execute now. But before we even go and

16:49

execute the plan, I already have an opportunity to evolve

16:53

my system.

16:54

Because, sure, every time it creates a plan that is

16:57

too long, I could just ask it to make it

16:59

more concise. And it didn't take that much overall. But

17:02

it still was annoying to have to do this and

17:05

it might have made some mistakes through condensing things that

17:07

it wouldn't have if it just made it the right

17:09

line length from the get go. And so this is

17:12

what I'm gonna show you right now. We're going to

17:14

evolve our system. It's a simple example of evolving, but

17:17

it still counts. And so I'm gonna go into the

17:19

plan template command,

17:21

and I'm going to read through this and think

17:23

where should I fix the problem that we just had?

17:26

It made something that was way too long.

17:29

And yeah honestly I'm just gonna tack it on the

17:32

top of this file here. So

17:34

make sure the structured

17:37

plan you create is between

17:40

507

17:42

hundred lines long.

17:44

You have failed

17:46

if you create a plan that isn't within

17:50

this range. And so this is kind of just off

17:52

the cuff here a couple of sentences that I want

17:54

to add but the point I'm driving across here is

17:56

that there was a mistake.

17:58

Let's correct the system. So it's not just a 1

18:01

off request from us, but now going forward, we shouldn't

18:04

hit that again. And if we do for whatever reason,

18:07

then we just come back and figure out, okay, how

18:09

do we have to prompt it so it actually doesn't

18:11

do that again. That is the opportunity that we have

18:13

here. And maybe we just update the command

18:16

and don't even do a 1 off fix as well.

18:19

Maybe we and I'll show you what you could do

18:20

here is,

18:21

this plan sucks.

18:24

Alright. Go back to the latest commit

18:28

and retry making the command. Or I could just say

18:31

go back to the latest commit and then I would

18:34

create the plan again and go through the Vy planning.

18:36

So that's why we have a save state with the

18:39

slash commit command

18:41

before we go through the Vybe planning, before we create

18:43

our structured plan. Because now any mistakes that we have

18:46

here, we can simply go back and try again. And

18:49

we're gonna do a commit right here, right now. Because

18:53

now we have our plan and we're happy with it,

18:55

I want to commit it so that when I go

18:58

through the implementation, if there's anything in the execution that

19:00

gets messed up, well, I'll just go back to where

19:03

I have the plan and that's it. And then I

19:05

will try again. That's the beauty of it. We evolve

19:08

our system and then either do a 1 off fix

19:11

or revert and try again with the new system. So

19:14

our commit is done. We have our save state that

19:17

we can revert back to if anything goes drastically wrong

19:20

in our implementation. And so speaking of implementation, let's get

19:23

into it now. So I have my structured plan which

19:26

conveniently has a part of my plan template command. I

19:29

have it placed within my dot agents folder within a

19:32

new folder created called plan. So I'm continuing to just

19:35

keep all of my context very organized. I think that

19:37

is super important

19:39

just to have that good hygiene or you are gonna

19:41

get lost in your code base and your coding assistant

19:44

is also going to get lost in all the context

19:47

that you have. And so with that, let's get into

19:49

the execution.

19:50

And so I'm not even gonna use my execute command

19:53

yet because I'm gonna cover that more in module 6

19:56

when we go through the pivot loops focused on implementation

19:59

specifically. So right now I'm gonna do it more like

20:01

I did in module 2 where it's just prompted out.

20:04

I want you to read the plan.

20:05

I want you to go through all the references there

20:08

and think through the validation,

20:09

go through the to do list that we have in

20:11

the implementation plan and knock things out task by task.

20:14

So keeping it very simple right now

20:17

and just focusing on the planning phase.

20:20

Alright. Our implementation

20:22

is now complete, and it even gives us in the

20:25

summary here the instructions for how we can get this

20:27

up and running ourselves to test the API endpoint manually

20:31

so we can see the agent in action now. And

20:34

if it doesn't do this for whatever reason or if

20:35

it's not detailed enough, like, maybe you don't know what

20:38

you have to add to your environment variables, you can

20:40

always say, how do I run this myself? Right? Like,

20:42

you can even just ask follow-up questions

20:44

to have it guide you through the manual testing and

20:47

the code review like I've talked about with the PIV

20:49

loop before. So very cool. So I got my environment

20:51

variable set up including the anthropic API key because we

20:54

are using Claude Haiku 4.5 as our model.

20:58

And then I ran the steps that it instructed me

21:01

on here. I have the agent running on port 8097.

21:05

So just a simple test API endpoint to talk to

21:07

this agent, which again, right now, no tools. It's just

21:10

a system prompt and connected to my LLM.

21:14

And so now I can do a simple test by

21:16

just running a curl to

21:18

my slash agent slash chat endpoint.

21:21

And for,

21:22

Windows on PowerShell, it's a little bit different. So I

21:24

just had the coding assistant help me with this command

21:27

right here. But, yeah, let's see. This is our our

21:29

final test here. We're not gonna do much validation right

21:32

now because that's more on module 7, but I just

21:34

wanna, like, see it at a high level before we

21:36

close off this PIV loop and then we'll do another

21:38

PIV loop to go into planning in even more detail.

21:41

So go ahead and hit enter here, and here's our

21:44

moment of truth. Boom. There we go. Hello. I'm Patty,

21:48

your AI assistant for Obsidian Vaults. Help you here to

21:50

help you with blah blah blah. Okay. Looking really, really

21:53

good. So it gives us kind of like the raw

21:55

text here, But that's all I need for my simple

21:57

validation right now. It's not supposed to be a really

22:00

nice CLI to talk to the agent yet. We're just

22:03

hitting the API endpoint. And then for the next PIV

22:06

loop, we're gonna make it possible to connect this agent

22:09

directly into our obsidian vault. So I'll get more into

22:12

planning there. We'll actually get it to the point where

22:14

we have something very cool to test and so that's

22:16

gonna be the next video as we continue to do

22:19

yet another pivot loop to cover planning more. So I'll

22:21

see you in the next video for that.