---
course: Dynamous Agentic Coding
module: 4
lesson: "4.2"
title: "The Optimal Structure for Commands"
type: lecture
status: raw
date_added: 2026-02-18
date_modified: 2026-02-18
tags:
  - dynamous
  - agentic-coding
  - module-4-commands
  - command-structure
key_concepts: []
prerequisites: ["4.1"]
related_lessons: ["4.3", "4.4"]
---


Alright. Now that you know what commands are and how

00:02

they work, let's talk about how we can structure and

00:05

build them. If you had a dime for every time

00:08

I said mental model in this course, you would be

00:11

rich because I have another mental model for you, which

00:14

I just love them because they help us think through

00:16

something

00:18

systematically,

00:18

making it a lot easier for us to think about

00:21

what goes into all the processes that we define in

00:24

our commands. So that's what I wanna cover with you

00:26

in this video. You can take this mental model to

00:29

help you structure your command pretty much no matter what

00:32

the process is and even give that to your AI

00:35

coding assistant to help you build these commands just like

00:37

we use AI to help us build our layer 1

00:39

planning context. So zooming in here, the most important rule

00:43

that I want us us to pay attention to when

00:44

we're building our commands in this way is to think

00:47

from the agent's perspective.

00:49

That's why I have important in all caps here, which

00:51

if you didn't know, when you have important somewhere in

00:54

your prompt to a coding assistant or just any LLM,

00:57

it's actually proven that the text following the LLM is

01:00

gonna pay more attention to. So that's just a little

01:02

joke. That's why I have it here for us. And

01:04

so the primary mental model for building commands is we

01:06

define the input into the command.

01:09

We define the step by step process and then we

01:12

have our output format. What do we want the agent

01:14

to communicate

01:16

after the command has finished? Like the research it did,

01:18

the code that it changed, whatever that might be.

01:21

And the reason that this relates to the agent's perspective

01:25

is when we design our commands, we wanna think about

01:28

in the middle of the process here, what is all

01:30

the context we need? What does the agent actually need?

01:34

That's the input.

01:35

And then for the output, the reason we wanna think

01:37

about the agent's perspective here is because it's not always

01:39

going to be us

01:41

consuming the output of executing a command. And this is

01:43

a bit of a teaser for what's coming in the

01:45

rest of the course,

01:46

but sometimes when we invoke a slash command, like this

01:49

is a single slash command, we are gonna be the

01:51

ones to read the output. And I'll show you examples

01:53

of that later in this module as well. But other

01:56

times, the output of 1 command is gonna go directly

01:59

into the input of another command, kind of like another

02:01

coding assistant. So it's like an agent communicating with another

02:05

agent and this is command chaining. Very, very exciting. We'll

02:08

get into this later in the course when we really

02:10

start to automate our workflows

02:12

and make our system truly autonomous. But like I said,

02:15

I want to get progressively

02:17

more autonomous

02:18

throughout this course. Right now, I wanna focus on individual

02:21

commands, defining them and executing them. And so that's what

02:25

gets us into our process right here. Which by the

02:28

way, if you want an example of input process and

02:31

output, I kinda snuck that in here in the example

02:34

that I showed in the last video. This slash command

02:37

defines this structure exactly. I even call it out. Like,

02:39

the context

02:40

is the input. The process here is the step by

02:43

step we wanna do, and we invoke this command. And

02:45

then the output format is providing communication to us as

02:49

the human, at least in this case, like for each

02:51

issue found describing the problem and suggestions to fix it,

02:55

for example. And so all of the commands

02:58

that I'll show you in this module and in the

03:00

rest of the course,

03:02

it is going to follow this format. So it's very

03:05

important we understand

03:06

what defines each of these. And so starting with the

03:09

input, we want to think what does the agent need

03:11

to see. And this obviously can include a lot of

03:14

different things. It can include context around the process,

03:18

which that's mostly what we have defined right here. Right?

03:20

Like, here's the programming language. Here's the library for validation.

03:23

Here's what we're doing for testing. Right? That's context around

03:26

the process.

03:27

We have context specific to right now. That is generally

03:30

the parameters. Right? Like, this is a specific issue

03:33

we want to fix or this is the specific tool

03:36

that I want to implement with the create tool command.

03:39

We also have the persona for the agent, how we

03:41

want it to act. Like, maybe we have a a

03:44

slash command that we want to be less structured and

03:46

it's just more exploring our code base. Or maybe you

03:48

want it to be very, very precise. Right? Like, we're

03:50

in the planning stage. We're creating that structure plan and

03:53

we need it to be very precise. And so it's

03:55

just kinda part of the system prompt here, just describing

03:57

the persona that we wanted to take on when it

03:59

is going through this process. And then we also have

04:02

the parts of the conversation to pay attention to. This

04:04

1 is a little bit more specific, but what I

04:06

mean by that is sometimes you'll invoke a command in

04:09

the middle of a longer conversation you have with the

04:11

coding assistant. And so you might want to specify, like,

04:14

when this command is invoked in a longer context window,

04:17

here are the different things throughout the conversation that you

04:19

should focus on.

04:20

And then also how you wanted to make assumptions if

04:23

necessary.

04:24

And part of these commands and really all of our

04:26

layer 1 planning is to reduce the number of assumptions

04:29

as much as possible. But no matter how much we

04:31

try, there's still gonna be some assumption that it has

04:33

to make. And so you can kinda talk about that

04:36

as a part of the context if you want. Generally

04:38

though, these are the core 3 that you're going to

04:41

be focusing on most of the time when you're defining

04:43

the input for your commands. And the golden nugget that

04:47

I have for you here, and I have 1 for

04:48

each part of our structure,

04:50

is the input

04:52

is where you specify the layer 1 on demand context

04:55

that you want to pull. So thinking back to our

04:58

create tool command, this part right here where we're referencing

05:01

our guide to building tools, this is a part of

05:03

the input to our command. Now obviously, this command is

05:06

like so short that we don't even really have input

05:08

process and output, but I'm just showing you an example

05:11

of how we have layer 1 context pulled in as

05:14

a part of the input to our command.

05:17

And then after input, this is when we go right

05:19

into the process. So we have the context we need

05:22

to now get into the step by step.

05:25

And so what should the agent actually do in this

05:28

case? And so we can instruct the agent on the

05:30

step by step process to follow. This is the workflow

05:33

in our system. This is the main thing. And then

05:36

as a part of the step by step process, we

05:37

can talk about, what to research or analyze, like, in

05:41

our code base or on the web, how to manage

05:43

the tasks. Like, maybe we have a task management tool

05:47

that we're building into this workflow.

05:48

What kind of tools should it use? Like, should it

05:50

use the GitHub CLI? Are there MCP servers that we

05:53

have connected? More on that in another module in this

05:55

course. What kind of code changes to make? This is

05:59

really just our process.

06:01

And, yeah, commands are the core of our system because

06:05

the processes build up the workflows that really defines our

06:09

system. And so we can even chain them together, which

06:11

is the teaser I showed you for what is coming

06:14

next. That's the golden nugget that I have for process.

06:17

And then for output, this is very important because we

06:20

also wanna think, is the output gonna be something that

06:23

we consume or is it going to be something that

06:25

another system or another AI coding assistant consumes?

06:29

And so when we go through the exercise for this

06:31

module in a couple of videos, we'll get into that

06:33

a bit more. But, yeah, it's important for you to

06:36

think what should the agent share and is this for

06:38

us or is this for another agent. And so this

06:41

can be like the code analysis that it did, architecture

06:44

recommendations if it's a sort of planning command, it can

06:47

be the code implementation plans like a structured plan like

06:50

we saw in the PIV loop. It can be structured

06:53

documents

06:54

which markdown is always preferred. So you can have commands

06:56

produce documentation

06:58

as markdown documents

06:59

and then summary of code changes made if it is

07:02

a plan that is doing some kind of implementation. Right?

07:04

So, like, this is very specific to the type of

07:07

command

07:08

that you are invoking, and we'll get into the different

07:10

types in the next video. And so the golden nugget

07:13

here is prompt engineering

07:15

is super important. The output quality determines how well the

07:19

command fits in with the rest of the system. Like,

07:21

if you have a command to implement something in the

07:24

code, like creating a tool, for example,

07:26

but the agent doesn't clearly describe what was changed. Now

07:29

if we go into a second command that's gonna validate

07:32

the tool, it doesn't even know what to validate. Right?

07:34

Like, it's very important to be very specific

07:37

in these different things that we want the agent to

07:39

output.

07:40

And the last thing that I have here, and you

07:42

might have seen this text of above each of these

07:45

categories,

07:46

is that I have the context engineering pillars

07:49

that each of these apply to. And this is actually

07:52

really cool. The 4 pillars of context engineering applies to

07:55

a lot more than just structured plans like we talked

07:58

about in the PIV loop. And, obviously, that is important,

08:01

but, really, context engineering applies to any prompting that we

08:04

do, including the processes in our commands. So we care

08:08

about RAG, memory, task management, and prompt engineering,

08:12

and all of these 4 apply to different parts of

08:15

our process. So, like, for input, for example,

08:17

we care about memory and prompt engineering. Those are the

08:20

2 pillars that apply here because

08:22

memory, we might be leveraging part of our conversation

08:25

as context for the command. And then obviously prompt engineering

08:29

because when we're defining all this context, like, the all

08:32

the input right here about the project and, you know,

08:34

specific things like our parameters, that all counts as prompt

08:37

engineering.

08:38

And then for our process, it's reg tasks and then

08:42

prompt engineering as well. Right? Like all of our structure

08:45

that we define here for this reasonable prompt is prompt

08:48

engineering. But then we have tasks because we're talking about

08:51

how to manage tasks in the step by step process.

08:54

And then we have reg because depending on the command,

08:57

we might also be speaking to what we wanted to

08:59

research and analyze in our knowledge base, over the Internet,

09:02

analyzing our code base, whatever that might be. And then

09:05

finally, for output, it really is just prompt engineering. Right?

09:08

That's why I said as a gold nugget that it's

09:10

super important here because the only thing that we're doing

09:13

here is nothing with tasks, nothing with rag or memory.

09:15

We're just trying to be very specific

09:18

what we want the coding assistant to output when it

09:20

finishes this process. And also, in the folder for this

09:23

video and the repo, I've got a read me that

09:24

you can read through if you want, covering the input

09:26

process output framework. Pretty much what I've covered in this

09:29

video, but just another resource for you. And then I

09:31

have the example command that we have in the Excalidraw

09:34

that outlines the input process and output. And here's the

09:38

thing, Literally, you can just take this idea of like

09:41

input process output, give it to an AI coding assistant

09:44

and have it help you build much better commands than

09:48

if you just asked it to automate x y z.

09:50

Right? Like, you'll go into the AI coding assistant and

09:53

say, I wanna build a command or a process for

09:55

x y z. Make sure you have very detailed input,

09:59

a step by step process, and then an explicit output

10:01

format. And just giving that alone to your coding assistant

10:05

is helps so much when you use it to help

10:07

you build out your commands to start to create your

10:10

system, your workflow library. And the other thing that I

10:13

wanna say, and this is a bit of a teaser

10:14

going into the next video, is all of the commands

10:17

that I'll create with you and for you throughout the

10:20

rest of this course,

10:21

they follow this format. Like our execute command, for example,

10:25

to take a structure plan and write out all the

10:28

code for it. I don't explicitly

10:30

call out input process and output anywhere in this file

10:34

like I do in that other example command,

10:36

but it's all here. Right? Like, this is our output

10:38

format. This is the equivalent of the output section

10:42

of the example command. And so I am always,

10:45

always following this structure and I'd highly recommend that you

10:49

do the same. Alright. So the last thing that I

10:51

wanna hit on here is why I didn't just start

10:53

with commands out the get go. The first time I

10:55

did the PIV loop with you in module 2. And

10:57

I actually did that very purposely. Like I said earlier,

11:00

I wanna get progressively more autonomous with our system throughout

11:04

this course because it's all about trust.

11:07

When we are first creating our prompts,

11:10

we're not really confident enough to turn them into reasonable

11:14

prompts yet. Right? Like it's our first time doing planning

11:16

or our first time doing validation.

11:19

And so at that point, it's okay to just manually

11:21

prompt that at first, but then when you start to

11:22

see yourself retyping the same thing over and over, that's

11:25

when it screams to you like, alright, let's go and

11:28

create the command now. That's how you start to build

11:30

up your command library because you see the things that

11:32

you're retyping and you're starting to build your own set

11:35

of processes that you want to define as your commands

11:38

following this format. So you do that once you trust

11:42

your prompts. That is when you turn them into commands.

11:45

And then the next level of trust is once you

11:48

have used these commands enough times where you trust that

11:51

the coding assistant,

11:52

given the instructions and following this process, it actually does

11:55

what you want it to do. And once you have

11:58

that level of confidence and it might take using the

12:00

commands 10 times, might take using them 50 times, that's

12:03

when you can start to string them together. And this

12:06

takes another level of trust because when we have the

12:08

output of 1 command chain directly into the input for

12:11

another, we are taking ourselves

12:14

out of the loop. And so we don't necessarily know

12:17

what's going on here anymore. And you can definitely add

12:20

in human in the loop even with command chaining, and

12:22

we're gonna get into that in a few modules from

12:26

now, in the next release batch. So stay tuned for

12:28

that. But right now, we'll get there once we are

12:31

confident in the system that we're starting to create with

12:35

these individual commands. So we'll define our commands, we'll invoke

12:37

them individually,

12:39

and be a part of the process. Right? Like, we'll

12:41

always be in the middle

12:43

of using our commands in this module and in the

12:46

next couple of modules, but then eventually, we'll graduate to

12:49

this point. And I want you to follow along with

12:52

me getting more and more autonomous as we build our

12:55

trust. So with that, we'll go on to the next

12:57

video now where I'll start to introduce you to common

12:59

commands and help you build up your command library.