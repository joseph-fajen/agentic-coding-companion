---
course: Dynamous Agentic Coding
module: 6
lesson: "6.2"
title: "Implementing with Multiple PIV Loops & Evolving Our System"
type: lecture
status: raw
date_added: 2026-02-18
date_modified: 2026-02-18
tags:
  - dynamous
  - agentic-coding
  - module-6-execute
  - multiple-piv-loops
  - system-evolution
key_concepts: []
prerequisites: ["6.1"]
related_lessons: ["7.1"]
---

Alright. So with our system really starting to come together,

00:02

let's go through 2 more PIV loops. I'm gonna add

00:05

a tool to our agent for each loop. And so

00:08

at this point, our Obsidian AI agent is really just

00:10

an LLM chatbot embedded into Obsidian. It doesn't have any

00:14

capabilities yet, and so I wanna add those right now.

00:16

This will be when our agent really starts to become

00:19

useful.

00:20

And so in my commands folder, I've got the new

00:22

execute command that we just went over and then the

00:24

plan feature, which is based on the solution from the

00:27

last exercise. So I'm ready to go into the PIV

00:29

loop again, but it's gonna be even smoother than you've

00:32

seen before because we are evolving our system, adding more

00:35

commands and refining them. And so I'm gonna start with

00:38

priming just like I always do when working on an

00:41

existing code base. But we also get to use the

00:44

prime tools command specifically because finally, we're adding tools to

00:48

our agents. So this is the 1 that is very

00:50

similar to our generic primer, but we are calling out

00:52

our on demand context that we have in our reference

00:55

folder for our guide to adding tools based on that

00:58

expertise we brought in from Anthropic, their guide to writing

01:02

tools. We're incorporating that as part of our layer 1

01:04

planning. And so I'm gonna kick this off right now,

01:07

and it'll do all the other usual planning that it

01:10

does or priming rather, where it's just going through our

01:12

PRD and our README and all that. So I'll come

01:14

back once that is done. Alright. Our priming is complete

01:17

and now the first thing that I always love to

01:19

do when I'm going into the Vybe planning stage is

01:21

just ask based on the PRD, what tool

01:25

would it make sense to implement first? And so maybe

01:28

I already have an idea in my mind for what

01:30

I wanna start with, and I actually do. But just

01:32

more for the exercise of things, I wanna show you

01:34

what it looks like even if you have no idea.

01:36

Like, let's just go back to the plan, use that

01:38

as our North Star for what we want to accomplish

01:40

next. Alright. So based on the PRD, it's suggesting that

01:43

we should start with the Obsidian Query Vault tool. It's

01:46

the safest, provides immediate value, validates our entire integration stack.

01:50

And I completely

01:51

agree with this. I'm really glad this is the 1

01:53

I picked out from the PRD out of the 3

01:56

core tools that we have in there right now. And

01:57

so I have this prompt already crafted here to continue

02:01

with our vibe planning here. So I want to do

02:03

some back and forth, some research before we get into

02:06

creating our structured plan. So, yes, let's go with that

02:08

tool. Let's do some research. No implementation yet. And we

02:12

want to really think through how we are going about

02:15

implementing this tool. Also calling out some more of our

02:18

layer 1 on demand context, like our vertical slice architecture

02:21

patterns. We have the MVP tool design that we built

02:25

recently. And so combining that all together and then asking

02:27

it to do some research on Pydantic AI because that

02:30

is our agent framework. We need to make sure we're

02:32

building tools the right way with Pydantic AI. So I'm

02:35

gonna send this off. It's gonna do a bunch of

02:37

research. When we come back from this, I'm just gonna

02:39

call the Vybe planning there, then we'll get onto creating

02:42

our structured plan. Looking really good. So I did a

02:44

ton of research on PyDantic AI like I asked it

02:47

to. I read through this output off camera and it

02:50

looks fantastic.

02:52

The 1 thing I noticed is it didn't say explicitly

02:54

or at least I didn't see where it read through

02:56

my other on demand context, so I just asked it

02:58

really quick, which that's a little gold nugget for you.

03:00

You can always just ask it, like, let me know

03:02

what context you already have in this conversation. And sure

03:05

enough, it does have everything. So cool. To keep things

03:08

brief, I'm gonna go right into creating our structure to

03:10

plan here. And 1 thing I wanna say here is

03:13

that there is often a lot of gray area. What

03:16

when do we do research in

03:18

the Vibe planning stage versus just giving it to the

03:21

coding assistant to do in the research part of our

03:24

planning command?

03:25

And what I'll say is I wanna do most of

03:28

my research in the Vibe planning, especially because this is

03:31

your place to ask questions to, like I always say,

03:34

get on the same page with the coding assistant for

03:36

what you're going to develop. And so I've done a

03:38

lot of my research already.

03:40

Now going into the planning

03:42

and creating the structured plan, I just have a couple

03:44

of things that I wanna mention here. Like, how I

03:46

wanted to name things very clearly, making sure that we

03:49

update the system prompt, right, like, all my last considerations

03:51

before I send it off into creating the structured plan.

03:54

And then we can always validate the structured plan and

03:56

refine and iterate on that going forward as well. So

03:59

looking really nice. And then by the way, in the

04:00

description, I'll link to all of these prompts that I

04:03

have in order. So if you wanna, like, go through

04:04

my entire flow for the PIV loops that I'm doing

04:07

in this video, you can do that. So I'm documenting

04:10

everything for you as I'm going through this process that

04:13

is very, very smooth. So there we go. Kicking off

04:15

our plan feature. And so I'll come back once it's

04:18

done all the research and created our structure plan. Alright.

04:21

We have our structure plan and our coding assistant is

04:24

very confident that we can knock it out in 1

04:25

go because it is just 1 little iteration of the

04:28

PIV loop. But we have a problem here that I've

04:31

left in on a purpose. If we go to the

04:34

structure plan that we just created and scroll all the

04:38

way down, it is a grand total

04:40

of 1752

04:43

lines long. That is incredibly ridiculous.

04:46

Way too long. And so going back to our

04:50

planning command here, there's probably something we have to do

04:52

to evolve our system in this place. So whenever we

04:56

encounter an issue in the planning or the implementation validation,

04:59

whatever, we just need to think like where should we

05:01

adjust? Should we do something in our rules? Like, maybe

05:04

it's actually our global rules that need to be fixed

05:07

or something in our layer 1 planning. Like, maybe for

05:10

some reason in our reference,

05:11

the tool guides, it said to make our plans really

05:14

long. I mean, obviously, not that's not the case. But

05:16

I'm just saying you wanna think about, like, at what

05:18

point do I need to go to this part of

05:20

the system and fix it. And so in this case,

05:22

it's nice and obvious

05:24

that it should be something that we add into our

05:27

planning command.

05:28

And so if you remember back to last module, for

05:31

the plan template command,

05:33

the simpler 1, I added something to the top that

05:36

told it to be more concise. Right? Like, I wanted

05:38

my plan to be between 507

05:41

hundred lines long. And this is such a simple issue

05:43

that I I could just add that in manually again

05:46

right now, but I wanna show you what it looks

05:48

like. To use an AI coding assistant to reflect on

05:52

an issue

05:53

and think about how we could evolve our system using

05:55

it to help us. Because sometimes

05:58

the issue might not be so obvious. For demonstration purposes,

06:02

I I do like that the problem here is so

06:04

clear and the solution is so clear. But let's just

06:07

think for a second if this was a lot more

06:10

of a trickier

06:11

situation here, where it screws up something in the implementation

06:14

and we don't even really know where to start looking

06:15

at, like, what we'd have to change in our rules

06:17

or our system, whatever that might be. And so going

06:20

back here, I'm gonna send in another prompt. It's very

06:22

simple. This plan is way too long. It needs to

06:25

be a lot more concise. And then this is the

06:27

keyword that I love using, meta reasoning. Do some meta

06:30

reasoning here. Like, I don't want you to fix the

06:33

problem yet, though I will have it do that in

06:35

a second. But help me understand why the plan is

06:37

so long and how I can adjust the plan feature

06:40

command

06:41

to avoid this in the future.

06:43

Or maybe I'm not even that specific here, and I

06:45

would say, like, look at my commands, look at my

06:47

rules, and see what I might need to adjust. And

06:49

so it's not gonna update the plan yet, but it's

06:52

going to tell me what can I change in my

06:55

command specifically? This is how we can evolve our system.

06:58

Every mistake is an opportunity to make our system better.

07:01

So we got some suggestions from our coding assistant how

07:04

to update and evolve our system. I don't think we

07:07

have to do this much though actually. So I'm gonna

07:09

go into Aquavoice and say,

07:12

I like your thought process here. I think we can

07:14

actually keep this very simple. We just need the hard

07:16

constraint number 1. So I want you to put the

07:19

hard constraint at the top of the plan feature

07:22

that it needs to be between, let's just say 507

07:25

hundred lines long. But everything else like the detailed task

07:29

subsections, I think are good. So let let's keep that.

07:31

Let's just do a simple fix here.

07:33

And then after you do that simple fix, I want

07:36

you to make this structure plan between 507 hundred lines

07:40

long and make it very concise while still keeping it

07:43

comprehensive. Alright. Good. So I'll go ahead and send that

07:45

in. Another thing you can do by the way is

07:47

after you evolve your system,

07:49

since we have a save state at every point, right,

07:51

like after every plan, we do the commit command. After

07:54

every feature implementation, we do the commit command. You could

07:57

also ask it to go back to the latest commit

08:00

and retry creating the plan. So we could just wipe

08:03

it entirely. You can do the same kind of thing

08:04

with implementation. So we can leverage save states, leverage that

08:08

part of our system where we are committing

08:10

and taking advantage of that. But right here, I'm just

08:12

gonna do this because

08:15

cause it's nice and simple. So, yeah, very simple addition

08:16

to our plan and then we'll make our current structure

08:19

plan more concise.

08:21

Now our structure plan is looking a lot better. In

08:24

fact, it even went below the new limit that I

08:26

gave it, which it says here that the plan is

08:29

fully comprehensive even at this many lines. And that actually

08:32

makes sense to me. Right? Like, we're doing mini PIV

08:35

loops for a reason. We want to be very granular

08:37

in what we're implementing because that's always gonna be the

08:39

most reliable. And so, yeah, I think that actually makes

08:42

sense to me. And I scrolled through this very briefly

08:45

off camera, and we have all the core sections we

08:47

need, the context to reference, especially integration points in our

08:50

code base. We have the step by step tasks, all

08:53

the files that it has to create and edit. We

08:55

have all the validation that we're gonna go through, which

08:57

we'll cover that more in detail in the next module.

09:00

So, yeah, this is looking really good. And so usually,

09:03

I'll iterate more on the plan, but for the sake

09:06

of brevity here, I'll go slash execute and we'll go

09:09

right into implementing our plan now. This is our execution.

09:14

And so I will copy the path, the relative path

09:17

to this file and just paste it in. There we

09:19

go. So the new structured plan. Go ahead and send

09:22

this off. And besides

09:24

creating the execute plan itself, there's not that much to

09:27

cover as far as systems for executing because it really

09:30

is that simple when we put all of our work

09:33

into planning already.

09:35

And so that's why I'm spending time talking about evolving

09:37

the system structure

09:40

plan. Maybe there'll be something wrong with the code implementation

09:43

as well.

09:44

We'll see how it looks. After it's done implementing here,

09:47

we'll go back into Obsidian and we'll test it with

09:49

the new tool. Alright. Our implementation

09:51

is complete. We have the first tool added to our

09:54

Obsidian agent and gave me a nice summary at the

09:56

end. I like to ask for something really concise often

09:59

as well. And then just also advice for how I

10:01

can run everything and if I need to change anything

10:03

in my environment after this feature implementation. So just another

10:07

little gold nugget for you there. So that's just the

10:09

quick summary here. And then I also ran a slash

10:11

commit just showing that end of our system. Though typically,

10:14

I would do this more after I have really validated

10:16

everything. But off camera, I did do some testing and

10:19

it was looking really, really good. So take a look

10:21

at this. Gonna open it up. I have Patty selected

10:24

already. I'll say what files or I could say what

10:27

directories

10:28

do I have in my vault. And this is like

10:30

blazing fast. It's doing the tool calls. You can see

10:32

it in the logs under the hood here. And there

10:35

we go. We got the agent decoding course

10:38

and Copilot custom prompts. I guess it called out these

10:40

as like the key folders that I have right now.

10:43

Here are the main ones I can see. And then

10:45

I have 121

10:46

notes in total. Very, very cool. Search for my,

10:50

let's say global rules Excalidraw

10:53

diagram. I wanted to find the 1 that I had

10:56

for module 3. Let's see if it can pull up

10:58

the exact file here. And there we go. So it's

11:00

a little messy right now. The first token is still

11:02

missing. There's some new lines that need to be here.

11:04

But, yeah, it found our file, Excalifor global rules. Very,

11:08

very nice. So our agent is working great. The new

11:10

tool and the streaming here, it's not perfect, but it's

11:13

looking really good. But I want to make this work

11:16

really, really well before I go on to the next

11:18

iteration of the pivot loop. But I generally recommend doing

11:21

that. Things aren't perfect here. We're still missing that first

11:23

token.

11:24

It looks like it tried different tool calls here, but

11:26

then in between the responses, it's not adding new lines.

11:29

And so I'm going to address this right now. And

11:32

so these things will cover quite a bit more going

11:34

into module 7 with validation.

11:36

And so we'll systemize the process I'm about to show

11:39

you right now because I want to, like I showed

11:42

once earlier, apply meta reasoning here to figure out exactly

11:45

why we're encountering these these issues so that we can

11:48

not just do a 1 off fix, but actually evolve

11:50

our system. There's probably something we need to update in

11:53

our layer 1 planning. Maybe our rules, maybe it's our

11:56

on demand context for working with Pydantic AI, whatever that

12:00

might be. We need to change the way that we're

12:02

handling the streaming here to fix these problems. So I'm

12:04

gonna go into Aquavoice,

12:05

and I'm going to say,

12:07

I want you to apply some meta reasoning here. I

12:10

have just pasted the output that I got when I

12:13

asked the AI agent to search for a file.

12:16

And so there's 2 main problems that I have here.

12:18

The first 1 is that we're missing the first token.

12:20

You can see from the response that it starts with

12:22

the didn't when the first token is I. And so

12:25

we're not streaming out the first token from the Pydantic

12:27

AI agent to the Obsidian

12:29

Copilot plugin. And then the second problem is we're missing

12:32

a bunch of new lines in between the different messages

12:34

that the agent is sending for us. And so we

12:36

need to add those new lines

12:38

after, each of the different responses between tool calls and

12:42

things like that. And so again, apply meta reasoning. Don't

12:45

make any changes yet. I want you to think about,

12:47

and really research why this issue is happening and then

12:50

think about what part of our context for the coding

12:53

assistant

12:54

we need to update. I want you to look at

12:55

our global rules at cloud dot m d, look at

12:58

all of the context that we have in the dot

13:00

agents slash reference folder,

13:02

look at our commands and our plan. I want you

13:05

to analyze things very deeply and figure out right now

13:07

what we need to adjust in our system so we

13:09

understand better how to stream tokens from the Pydantic AI

13:12

agent and give it to our Obsidian UI.

13:16

Alright. There we go. So it's a longer prompt, which

13:18

I can do. Thanks to Aquavoice or whatever your speech

13:20

to text tool is. But, yeah, this is really nice,

13:22

and things aren't formatted the best, but that's totally okay.

13:24

I'm gonna send it in. It'll know what I mean.

13:26

It'll do a bunch of research and figure out what

13:28

to address in our system so that we avoid this

13:31

kind of thing going forward, and we just evolve our

13:33

context to better understand how to work with the token

13:36

streaming. And this this kind of thing for AI agents

13:39

is generally 1 of the things that coding assistants mess

13:42

up on a lot, just how to handle tool calls

13:44

and token streaming, things like that. Okay. So it came

13:46

back with some pretty awesome suggestions, and it did a

13:49

lot of even writing some test scripts under the hood

13:51

to interact with the dot inter function with Padante AI

13:54

to figure out the exact problem with the code. So

13:56

it has the fix and it has some recommendations

13:59

for us to update our layer 1 planning as well.

14:01

And so it's suggesting to create some new on demand

14:04

context for how to handle streaming properly, which maybe I

14:07

would wanna add this because like I said, coding assistants

14:10

mess up on this kind of thing with agent implementations

14:12

a lot. And then also just adding a verification step

14:15

to our on demand context for the Obsidian Copilot setup.

14:19

So, yeah, I like these ideas overall.

14:21

But here's the other thing though. If we look at

14:24

the core problem that meta lessons learned, we had an

14:27

incomplete research report.

14:29

The core problem with all of the planning that we

14:31

did, it seems to actually have come down to an

14:34

issue

14:35

with some of our layer 2 planning.

14:38

Before we created our structured plan, we are just in

14:40

the Vy planning stage, we created a couple of these

14:43

documents, and it seems like they were incomplete. This 1

14:47

was incomplete, and that is the crux of the problem

14:49

that we have here. So through the help of the

14:52

AI coding assistant researching things for us, we have identified

14:55

exactly what part of our system is the problem. And

14:58

really it was part of our vibe planning. And so

15:01

I actually have an idea for this. Watch this. I'm

15:04

gonna go back into Aquavoice here and say,

15:06

actually I have a better idea for how we can

15:08

adjust our system. How about you add just a small

15:11

section to our plan dash feature

15:14

command that we have in the commands folder.

15:18

In this small section, I just wanna speak to any

15:21

of the reports that we create

15:23

during the planning phase or before we create our structure

15:26

plan. We should validate them. So read them, validate them

15:29

as a part of the research that we do in

15:31

the plan feature command.

15:33

Boom. Alright. Send that in. I think that's my idea

15:35

here. And really you could address this however you want.

15:37

Maybe you could go with its suggestion of creating some

15:39

more on demand context. Like we could kinda turn this

15:42

report

15:43

plus the fixes we did here into on demand context

15:46

for how to do streaming going forward. I don't think

15:48

I'm gonna touch that that much going forward. And so

15:51

I like this idea more of having a more general

15:54

fix of having our plan feature command

15:58

validate some of the research that we did. So kind

16:01

of like extending the research to do a bit of

16:03

research validation as well. And so I'm going to enhance

16:06

our system here and then we'll fix the core problem

16:09

for this implementation.

16:10

So now it has evolved our plan feature command and

16:14

this points out something very interesting.

16:16

This example that it has in our plan feature command

16:20

is pretty custom to building Pydantic AI agents. And that

16:23

points out something really important here, that the more you

16:26

evolve your system, oftentimes the more you are also customizing

16:29

it to your specific code base. And so you might

16:32

wanna have like a more general version of your commands

16:35

and then some that you've customized to your different code

16:37

bases for the different projects you are working on. I

16:39

mean, this is just an example. It's still a pretty

16:41

general command, but I think you get the idea what

16:44

I'm trying to get across here. And so with that,

16:47

I'm gonna say, great. Now fix this core issue. And

16:50

so now that we have our system evolved, I can

16:53

do this. And it's not just a 1 off fix

16:55

now because I've taken lessons from it to work for

16:58

things going forward. And then another thing you could do

17:01

is if the issue was bad enough, you could completely

17:05

wipe this current work. Right? Like I could go back

17:08

to the commit where I just have the plan and

17:10

I could completely retry.

17:12

Now in this case, I already ran the commit like

17:14

I showed earlier because I actually wanna create a save

17:16

state of that bad

17:18

version of the code base so that I can show

17:20

you in the next module how we can systematize

17:23

this process more. So the implementation has now been fixed.

17:26

Watch this. I'll ask it the same question. Search my

17:29

global rules Excalidraw

17:31

diagram. I want it to find this file specifically

17:34

and it's going to fail a little bit at first.

17:37

I noticed that it does this. It didn't find any

17:38

notes matching global rules Excalidraw diagram. Let me try a

17:42

broader search for just global rules, and then boom, found

17:44

it. The note is, and then I can click into

17:46

this, and it brings me right to the file. We

17:48

have the new lines that are looking a lot better

17:50

now. We're not missing the text at the start.

17:52

This is working really, really well. And so I can

17:55

also say, you know, like list the folders

17:57

and I can say all of them

17:59

in my vault. And so we can see it list

18:01

all folders. All of our tools for just querying and

18:04

and navigating our vault is working very, very well.

18:08

No. Tell me all of them. I wanna see every

18:12

single folder. Come on now. Boom. There we go. Okay.

18:14

Good. So 8 folders in total. Yes. Alright. Awesome. Alright.

18:17

So the very last thing that I wanna cover with

18:20

you is showing how fast we can go through the

18:22

PIV loop when we have a lot of trust in

18:24

the implementation

18:25

because we just built our first tool.

18:28

We understand

18:29

how to build the tool, what to look for with

18:31

the coding assistant. The coding assistant understands, and we even

18:34

evolved our system, at least to a small extent for

18:37

demonstration purposes. But when you really grind out a new

18:40

feature, you have quite a few opportunities usually to evolve

18:43

your system. And so when we do something similar, we

18:45

can go a lot faster. And so I'm going to

18:47

run the prime again,

18:49

and I'm gonna prime for tools specifically.

18:52

And then after this, I'm just gonna completely skip the

18:55

Vybe planning. I'm gonna go right into creating a structure

18:57

plan with my request for the next tool that I

18:59

wanna give just to show you that we can move

19:01

this fast as we are building more tools now. We'll

19:04

see that in the next couple of PIV loops throughout

19:06

the next 2 modules. Alright. Priming is complete. I'm just

19:09

gonna send in this request all at the same time

19:11

here. And it's very similar to

19:13

the first prompt we sent into the plan feature command

19:16

when we were building the query tools. But now we

19:18

want the Obsidian note manager so it can help us

19:21

move files around, edit files, delete files, all of that

19:24

good stuff. And so, yeah, having it research Piantic AI

19:27

again, giving it some more details of what I want

19:29

for the Obsidian note manager. I'm moving quick here. Just

19:32

showing you how fast we can go. Send this in.

19:34

Boom. And I wouldn't recommend going this fast. It's a

19:37

bit of an exaggeration,

19:39

but you can get the point that I'm really trying

19:40

to drive home here. So the plan is complete and

19:43

you know the drill. Now it's time to read the

19:45

structure plan, validate, and go back and forth as much

19:48

as we need to get this to the place where

19:49

we're ready to implement it. And I did some of

19:51

this off camera already because I've already shown you that.

19:54

I'm going through the PIV loop pretty quickly here just

19:56

to demonstrate again how fast we can go. And so

19:59

I'm gonna go slash execute and then the path to

20:02

the plan. Right click in my IDE,

20:04

copy relative path, paste it in, boom. Alright. Send it

20:07

in, and we are off to the races. And the

20:10

reason I'm able to go so fast is just because

20:13

the tool that we're building here is very similar to

20:16

the previous 1 we just built in the last PIV

20:18

loop. In fact, going through the conversation, and I was

20:21

watching as it was doing the planning as well. It

20:24

was referencing the previous tool. So it went through the

20:27

PRD,

20:28

and through the priming, it understood we already built 1

20:30

of the 3 core tools. Let me go and look

20:32

at that to see how we built it before. That's

20:35

why I'm able to have so much trust going through

20:37

this pivot loop a lot faster. Our implementation is now

20:40

complete. We have a ton of different capabilities now to

20:43

create notes, update notes, move folders, delete folders, all as

20:46

a single comprehensive tool following the guides from Anthropic. Again,

20:50

part of our on demand context. So this is phenomenal.

20:53

I'll just go into my Obsidian and test it a

20:55

little bit right now. I'm going to save most of

20:58

the validation for the next module.

21:01

And so I just want to try a couple of

21:03

tool uses right now. We're gonna keep refining things throughout

21:06

the course. You might have already noticed some things that

21:08

aren't ideal with this agent, but that's totally okay because

21:10

we're building it from the ground up. We'll get into

21:12

validation and involving our system and improving things in the

21:15

rest of this course. So I'll just say, create a

21:18

random note in my Copilot folder

21:22

with some random text. I just wanna try creating something

21:25

from scratch here with our new tool. And it's so

21:28

cool how blazing fast this is. There we go. We

21:30

already have our new note, random thoughts from today. It

21:34

even gave some tags and stuff, so that's pretty cool.

21:36

But anyway, I can say rename this now to and

21:39

I'll say, random note number 1. There we go. And

21:43

boom. It is already renamed. Blazing fast. And I could

21:47

poke around with more tools right now, but I wanna

21:49

keep this brief. Might not be the most interesting thing

21:51

for you. And we'll get into really validating these tools

21:54

in the next module.

21:55

And so speaking of that, that's all I have for

21:58

implementation. Next up, we have validation. This really was a

22:01

short module because

22:03

all of our work goes into the planning and validating,

22:06

and then sandwiched in the middle in the PIV loop

22:08

is what we give to the coding assistant. That's what

22:10

I was covering for the most part in this module.

22:13

And so getting into validation,

22:16

I'm going to bring some of the quirks and issues

22:18

up that we have in our agent right now, And

22:21

I'll show you how we can systematize

22:23

validating our implementations,

22:25

surfacing these issues, and fixing them. And then with that,

22:28

evolving our system to avoid these things and really just

22:32

elevating everything for all of our future implementations going forward.

22:36

So really exciting stuff. Validation is when things will come

22:39

together even more. So I will see you in the

22:41

next module for that.